import streamlit as st
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq
from loader import *
import tempfile
from langchain.prompts import ChatPromptTemplate

# Tipos e modelos dispon√≠veis
tipoArquivoValido = ['PDF', 'CSV', 'WebSite']
modelosConfig = {
    'Groq': {
        'modelos': ['llama3-70b-8192', 'llama3-8b-8192', 'mixtral-8x7b-32768'],
        'chat': ChatGroq,
    },
}

# Inicializa mem√≥ria no session_state
if 'memoria' not in st.session_state:
    st.session_state['memoria'] = ConversationBufferMemory()

# Carrega o conte√∫do do arquivo
def carregaArquivo(tipoArquivo, arquivo):
    if tipoArquivo == 'WebSite':
        documento = carregaSite(arquivo)
    elif tipoArquivo == 'CSV':
        with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as temp:
            temp.write(arquivo.read())
            nomeTemp = temp.name
        documento = carregaCSV(nomeTemp)
    elif tipoArquivo == 'PDF':
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp:
            temp.write(arquivo.read())
            nomeTemp = temp.name
        documento = carregaPDF(nomeTemp)
    else:
        documento = "Tipo de arquivo n√£o suportado."
    return documento


# Carrega o modelo e prepara a cadeia de conversa√ß√£o
def carregaModelo(provedor, modelo, apiKey, tipoArquivo, arquivo):
    try:
        documento = carregaArquivo(tipoArquivo, arquivo)

        if "Just a moment..." in documento:
            st.warning("O conte√∫do do site n√£o p√¥de ser carregado corretamente. Tente novamente.")
            return

        system_message = f'''Voc√™ √© um assistente amig√°vel chamado VagnerGPT. Voc√™ possui acesso √†s seguintes informa√ß√µes vindas de um documento do tipo {tipoArquivo}:
        ####
        {documento}
        ####
        Utilize as informa√ß√µes fornecidas para basear as suas respostas.
        Sempre que houver $ em sua sa√≠da, substitua por S.

        Se a informa√ß√£o do documento for algo como "Just a moment...Enable JavaScript and cookies to continue", sugira ao usu√°rio carregar novamente o modelo.
        '''

        template = ChatPromptTemplate.from_messages([
            ('system', system_message),
            ('placeholder', '{chat_history}'),
            ('user', '{input}')
        ])

        chat = modelosConfig[provedor]['chat'](model=modelo, api_key=apiKey)
        chain = template | chat
        st.session_state['chain'] = chain

    except Exception as e:
        st.error(f"Erro ao carregar modelo ou documento: {e}")


# P√°gina principal do chat
def pagina_chat():
    st.header('ü§ñ Welcome to VagnerGPT', divider=True)
    chain = st.session_state.get('chain')

    if chain is None:
        st.error('Carregue o modelo antes de conversar.')
        st.stop()

    memoria = st.session_state['memoria']

    # Exibe o hist√≥rico
    for mensagem in memoria.buffer_as_messages:
        chat_msg = st.chat_message(mensagem.type)
        chat_msg.markdown(mensagem.content)

    input_usuario = st.chat_input('Talk to me')

    if input_usuario:
        st.chat_message('human').markdown(input_usuario)

        # Executa o modelo e escreve a resposta em streaming
        resposta_stream = chain.stream({'input': input_usuario, 'chat_history': memoria.buffer_as_messages})
        resposta_chat = st.chat_message('ai')
        resposta_completa = resposta_chat.write_stream(resposta_stream)

        # Salva no hist√≥rico da mem√≥ria
        memoria.chat_memory.add_user_message(input_usuario)
        memoria.chat_memory.add_ai_message(resposta_completa)

        st.session_state['memoria'] = memoria


# Sidebar de configura√ß√£o
def sidebar():
    tabs = st.tabs(['üìÅ File Upload', '‚öôÔ∏è Model Selection'])

    with tabs[0]:
        tipoArquivo = st.selectbox('Select source type', tipoArquivoValido)
        if tipoArquivo == 'WebSite':
            arquivo = st.text_input('Enter website URL')
        elif tipoArquivo == 'CSV':
            arquivo = st.file_uploader('Upload CSV file', type=['.csv'])
        elif tipoArquivo == 'PDF':
            arquivo = st.file_uploader('Upload PDF file', type=['.pdf'])
        else:
            arquivo = None

    with tabs[1]:
        provedor = st.selectbox('Select provider', list(modelosConfig.keys()))
        modelo = st.selectbox('Select model', modelosConfig[provedor]['modelos'])
        apiKey = st.text_input('Enter your API key', type='password')

    if st.button('üöÄ Load Model'):
        if not arquivo:
            st.warning("Voc√™ precisa fornecer um arquivo ou URL.")
        else:
            with st.spinner("Carregando modelo e documento..."):
                carregaModelo(provedor, modelo, apiKey, tipoArquivo, arquivo)


# Fun√ß√£o principal
def main():
    with st.sidebar:
        sidebar()
    pagina_chat()


if __name__ == '__main__':
    main()
